{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.vocab import Vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Reviews.csv')\n",
    "df = df[['Score', 'Text']]\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates('Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Score                                               Text\n0      5  I have bought several of the Vitality canned d...\n1      1  Product arrived labeled as Jumbo Salted Peanut...\n2      4  This is a confection that has been around a fe...\n3      2  If you are looking for the secret ingredient i...\n4      5  Great taffy at a great price.  There was a wid...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count                                                393579\nunique                                               393579\ntop       This is the best cat litter box next to the Li...\nfreq                                                      1\nName: Text, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 1, 4, 2, 3])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels, reviews = df['Score'].to_numpy(), df['Text'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(arrays, ratios=(0.7, 0.2, 0.1)):\n",
    "    data_len = arrays[0].shape[0]\n",
    "    assert all(a.shape[0] == data_len for a in arrays[1:])\n",
    "    sizes = [r / sum(ratios) for r in ratios]\n",
    "    sizes = [int(s * data_len) for s in sizes[:-1]]\n",
    "    sizes.append(data_len - sum(sizes))\n",
    "    start = 0\n",
    "    finish = 0\n",
    "    splits = []\n",
    "    for s in sizes:\n",
    "        finish += s\n",
    "        splits.append([a[start:finish] for a in arrays])\n",
    "        start += s\n",
    "    return splits\n",
    "\n",
    "train, valid, test = split_data((labels, reviews), (0.7, 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_merge(data):\n",
    "    labels, text = data\n",
    "    return [{'label': int(l), 'text': row} for l, row in zip(labels, text)]\n",
    "\n",
    "train = data_merge(train)\n",
    "valid = data_merge(valid)\n",
    "test = data_merge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## tokenize text in datasets, add bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 275505/275505 [01:24<00:00, 3243.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_tokenize(data, tokenizer, lower, ngrams, cache=True):\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    for entry in tqdm.tqdm(data, 'lines', len(data)):\n",
    "        if lower:\n",
    "            entry['text'] = entry['text'].lower()\n",
    "        entry['text'] = tokenizer(entry['text'])\n",
    "        entry['text'] = list(ngrams_iterator(entry['text'], ngrams))\n",
    "    return data\n",
    "\n",
    "tokenizer = 'spacy'\n",
    "lower = True\n",
    "ngrams = 2\n",
    "\n",
    "train = data_tokenize(train, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 78715/78715 [00:24<00:00, 3154.55it/s]\n",
      "lines: 100%|██████████| 39359/39359 [00:12<00:00, 3069.20it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = data_tokenize(valid, tokenizer, lower, ngrams)\n",
    "test = data_tokenize(test, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## save all data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:06<00:00, 45648.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_tokenized(data, filename):\n",
    "    with open(filename, 'wt') as f:\n",
    "        f.writelines(json.dumps(l) + '\\n' for l in tqdm.tqdm(data))\n",
    "\n",
    "save_tokenized(train, 'train_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78715/78715 [00:01<00:00, 45678.30it/s]\n",
      "100%|██████████| 39359/39359 [00:00<00:00, 42899.17it/s]\n"
     ]
    }
   ],
   "source": [
    "save_tokenized(valid, 'valid_tokenized.json')\n",
    "save_tokenized(test, 'test_tokenized.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load train data from json if available"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:08<00:00, 34428.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_tokenized(filename):\n",
    "    with open(filename, 'rt') as f:\n",
    "        return [json.loads(l) for l in tqdm.tqdm(f.readlines())]\n",
    "\n",
    "try:\n",
    "    if train:\n",
    "        pass\n",
    "except NameError:\n",
    "    train = load_tokenized('train_tokenized.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:10<00:00, 26307.71it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data,\n",
    "                max_size=30000,  # x 100 emb_dim = about 3M model parameters\n",
    "                ):\n",
    "    counter = Counter()\n",
    "    for entry in tqdm.tqdm(data):\n",
    "        counter.update(entry['text'])\n",
    "    return Vocab(counter, max_size)\n",
    "\n",
    "vocab = build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## create torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████| 275505/275505 [00:27<00:00, 9935.62it/s] \n"
     ]
    }
   ],
   "source": [
    "class JsonDataset(Dataset):\n",
    "    def __init__(self, filename, vocab, preload):\n",
    "        self.filename = filename\n",
    "        self.vocab = vocab\n",
    "        self.label_dict = {i + 1: i for i in range(5)}\n",
    "        self.data_len = None\n",
    "        self.preload = preload\n",
    "        if self.preload:\n",
    "            self._preload_data()\n",
    "\n",
    "    def _preload_data(self):\n",
    "        with open(self.filename, 'rt') as f:\n",
    "            lines = [json.loads(l) for l in f.readlines()]\n",
    "        self.data = []\n",
    "        for l in tqdm.tqdm(lines, 'loading'):\n",
    "            label = l['label']\n",
    "            label = self.label_dict[label]\n",
    "            label = torch.tensor(label)\n",
    "            text = l['text']\n",
    "            text = torch.tensor(np.fromiter((vocab[token] for token in text),\n",
    "                                        dtype='int'))\n",
    "            self.data.append((label, text))\n",
    "        self.data_len = len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.preload:\n",
    "            return self.data[index]\n",
    "\n",
    "        with open(self.filename, 'rt') as f:\n",
    "            for i, l in enumerate(f):\n",
    "                if i == index:\n",
    "                    break\n",
    "        line = json.loads(l)\n",
    "        label = line['label']\n",
    "        label = self.label_dict[label]\n",
    "        label = torch.tensor(label)\n",
    "        text = line['text']\n",
    "        text = torch.tensor(np.fromiter((vocab[token] for token in text),\n",
    "                                        dtype='int'))\n",
    "        return label, text\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.data_len:\n",
    "            with open(self.filename) as f:\n",
    "                for i, l in enumerate(f):\n",
    "                    pass\n",
    "            self.data_len = i + 1\n",
    "        return self.data_len\n",
    "\n",
    "train_dataset = JsonDataset('train_tokenized.json', vocab, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████| 78715/78715 [00:06<00:00, 11287.58it/s]\n",
      "loading: 100%|██████████| 39359/39359 [00:03<00:00, 11306.73it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = JsonDataset('valid_tokenized.json', vocab, True)\n",
    "test_dataset = JsonDataset('test_tokenized.json', vocab, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "assert len(train_dataset) == len(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(4),\n tensor([    5,    23,   188,   509,    12,     3,     0,  1101,   168,    85,\n           309,     6,    23,   173,    41,    57,     9,    45,    12,    43,\n           272,     2,     3,    52,  1204,    68,    35,     7,  8561,    78,\n             7,  2457,   833,     6,     8,  1236,   134,     2,    18, 26061,\n            13,  6014,     6,   152,     0,    14,    52,   134,    78,    10,\n           213,     2,    73,  3763, 18810,  7085,    58,     0,     0, 28801,\n          1013, 11736,  4716,   641,  1355,  3619,  2450, 16407,   157, 19358,\n          5927,  3090,  2636,    99,   381,     0,     0,  1932,   474,     0,\n             0,  1422,     0,     0,  8115,   161,  3327,     0,  1193,   428,\n             0,     0,     0,     0,  1237,     0,     0,   137,     0,   496,\n             0,  5994, 12876]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create dataloaders for padded sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def padded_collate(batch, padding):\n",
    "    labels, texts = zip(*batch)\n",
    "    labels = torch.tensor(labels)\n",
    "    texts = pad_sequence(texts, padding_value=padding)\n",
    "    return labels, texts\n",
    "\n",
    "padding = vocab['<pad>']\n",
    "collate = partial(padded_collate, padding=padding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "batch_size = 126\n",
    "\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=4)\n",
    "valid_iter = DataLoader(valid_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=4)\n",
    "test_iter  = DataLoader(test_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## add fasttext model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self, vocab_len, embed_dim, n_classes, padding):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_len, embed_dim, padding)\n",
    "        self.fc = nn.Linear(embed_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # shape = [seq_dim, batch_dim, embed_dim]\n",
    "        x = x.mean(0)\n",
    "        return self.fc(x)\n",
    "\n",
    "vocab_len = len(vocab)\n",
    "embed_dim = 100\n",
    "n_classes = 5\n",
    "model = TextModel(vocab_len, embed_dim, n_classes, padding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "number of parameters and output shape - sanity check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of learnable parameters: 3000705\n"
     ]
    }
   ],
   "source": [
    "print('total number of learnable parameters: {}'.format(\n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output shape with batch size 126: torch.Size([126, 5])\n"
     ]
    }
   ],
   "source": [
    "for l, t in train_iter:\n",
    "    break\n",
    "output = model(t)\n",
    "print('model output shape with batch size {}: {}'.format(\n",
    "    batch_size, output.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    preds = preds.argmax(dim=1, keepdim=True)\n",
    "    correct = (preds == labels).sum()\n",
    "    total = preds.shape[0]\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def train(train_iter, model, optimizer, criterion, device):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for labels, texts in tqdm.tqdm(train_iter, 'train_batch'):\n",
    "        labels, texts = labels.to(device), texts.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(texts)\n",
    "        loss = criterion(preds, labels)\n",
    "        acc = accuracy(preds, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item()\n",
    "\n",
    "    return total_loss / len(train_iter), total_acc / len(train_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def evaluate(valid_iter, model, criterion, device):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for labels, texts in tqdm.tqdm(valid_iter, 'valid_batch'):\n",
    "            labels, texts = labels.to(device), texts.to(device)\n",
    "\n",
    "            preds = model(texts)\n",
    "            loss = criterion(preds, labels)\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc.item()\n",
    "\n",
    "    return total_loss / len(valid_iter), total_acc / len(valid_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "train_batch:   0%|          | 0/2187 [00:00<?, ?it/s]\u001B[A\n",
      "train_batch:   0%|          | 1/2187 [00:23<14:17:21, 23.53s/it]\u001B[A\n",
      "train_batch:   0%|          | 5/2187 [00:45<10:59:00, 18.12s/it]\u001B[A\n",
      "train_batch:   0%|          | 9/2187 [01:08<8:42:15, 14.39s/it] \u001B[A\n",
      "train_batch:   1%|          | 13/2187 [01:29<7:02:08, 11.65s/it]\u001B[A\n",
      "train_batch:   1%|          | 17/2187 [01:51<5:55:56,  9.84s/it]\u001B[A\n",
      "train_batch:   1%|          | 21/2187 [02:13<5:08:09,  8.54s/it]\u001B[A\n",
      "train_batch:   1%|          | 25/2187 [02:36<4:37:45,  7.71s/it]\u001B[A\n",
      "train_batch:   1%|▏         | 29/2187 [03:00<4:18:42,  7.19s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 33/2187 [03:22<4:00:08,  6.69s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 37/2187 [03:46<3:50:42,  6.44s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 41/2187 [04:12<3:51:04,  6.46s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 45/2187 [04:34<3:41:00,  6.19s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 49/2187 [04:56<3:32:14,  5.96s/it]\u001B[A\n",
      "train_batch:   2%|▏         | 53/2187 [05:17<3:25:16,  5.77s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 57/2187 [05:40<3:23:45,  5.74s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 60/2187 [05:43<2:32:21,  4.30s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 61/2187 [06:04<5:37:42,  9.53s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 64/2187 [06:07<4:04:27,  6.91s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 65/2187 [06:25<6:09:05, 10.44s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 68/2187 [06:30<4:32:57,  7.73s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 69/2187 [06:47<6:13:55, 10.59s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 72/2187 [06:54<4:47:51,  8.17s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 73/2187 [07:10<6:03:15, 10.31s/it]\u001B[A\n",
      "train_batch:   3%|▎         | 76/2187 [07:16<4:36:56,  7.87s/it]\u001B[A\n",
      "train_batch:   4%|▎         | 77/2187 [07:31<5:51:22,  9.99s/it]\u001B[A\n",
      "train_batch:   4%|▎         | 80/2187 [07:38<4:28:48,  7.65s/it]\u001B[A\n",
      "train_batch:   4%|▎         | 81/2187 [07:54<5:54:44, 10.11s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 84/2187 [08:01<4:35:32,  7.86s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 85/2187 [08:12<5:06:45,  8.76s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 88/2187 [08:25<4:18:49,  7.40s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 89/2187 [08:35<4:42:31,  8.08s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 92/2187 [08:48<4:05:02,  7.02s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 93/2187 [08:56<4:11:57,  7.22s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 94/2187 [08:57<3:11:16,  5.48s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 96/2187 [09:09<3:13:34,  5.55s/it]\u001B[A\n",
      "train_batch:   4%|▍         | 97/2187 [09:20<4:17:30,  7.39s/it]\u001B[A\n",
      "train_batch:   5%|▍         | 100/2187 [09:30<3:32:55,  6.12s/it]\u001B[A\n",
      "train_batch:   5%|▍         | 103/2187 [09:43<3:16:47,  5.67s/it]\u001B[A\n",
      "epochs:   0%|          | 0/100 [09:43<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-7066be40ec8f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'epochs'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mvalid_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-24-96c8345e46ca>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_iter, model, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtexts\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'train_batch'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/site-packages/tqdm/std.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1173\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1174\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1175\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1176\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m             \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    806\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    807\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 808\u001B[0;31m                 \u001B[0msuccess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    809\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    759\u001B[0m         \u001B[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    760\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 761\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    762\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    763\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/multiprocessing/queues.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    102\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mblock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m                     \u001B[0mtimeout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdeadline\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m                         \u001B[0;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_readable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__enter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36m_poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    413\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 414\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    415\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    416\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 920\u001B[0;31m                 \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    921\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    922\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileobj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/clearscale/lib/python3.7/selectors.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m             \u001B[0mfd_event_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "best_loss = None\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs), 'epochs'):\n",
    "    train_loss, train_acc = train(train_iter, model, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(valid_iter, model, criterion, device)\n",
    "\n",
    "    print('Epoch: {:03d}'.format(epoch + 1))\n",
    "    print('Training loss    : {:.5f}'.format(train_loss))\n",
    "    print('Training acc     : {:.2f}'.format(train_acc))\n",
    "    print('Validation loss  : {:.5f}'.format(valid_loss))\n",
    "    print('Validation acc   : {:.2f}'.format(valid_acc))\n",
    "\n",
    "    if best_loss is None or valid_loss < best_loss:\n",
    "        print('New best validation loss, saving model weights')\n",
    "        torch.save(model.state_dict(), 'textmodel5.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}