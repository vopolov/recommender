{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import linecache\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.datasets import TextClassificationDataset\n",
    "from torchtext.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Reviews.csv')\n",
    "df = df[['Score', 'Text']]\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates('Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Score                                               Text\n0      5  I have bought several of the Vitality canned d...\n1      1  Product arrived labeled as Jumbo Salted Peanut...\n2      4  This is a confection that has been around a fe...\n3      2  If you are looking for the secret ingredient i...\n4      5  Great taffy at a great price.  There was a wid...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count                                                393579\nunique                                               393579\ntop       This is the best cat litter box next to the Li...\nfreq                                                      1\nName: Text, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 1, 4, 2, 3])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels, reviews = df['Score'].to_numpy(), df['Text'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(arrays, ratios=(0.7, 0.2, 0.1)):\n",
    "    data_len = arrays[0].shape[0]\n",
    "    assert all(a.shape[0] == data_len for a in arrays[1:])\n",
    "    sizes = [r / sum(ratios) for r in ratios]\n",
    "    sizes = [int(s * data_len) for s in sizes[:-1]]\n",
    "    sizes.append(data_len - sum(sizes))\n",
    "    start = 0\n",
    "    finish = 0\n",
    "    splits = []\n",
    "    for s in sizes:\n",
    "        finish += s\n",
    "        splits.append([a[start:finish] for a in arrays])\n",
    "        start += s\n",
    "    return splits\n",
    "\n",
    "train, valid, test = split_data((labels, reviews), (0.7, 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_merge(data):\n",
    "    labels, text = data\n",
    "    return [{'label': int(l), 'text': row} for l, row in zip(labels, text)]\n",
    "\n",
    "train = data_merge(train)\n",
    "valid = data_merge(valid)\n",
    "test = data_merge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tokenize text in datasets, add bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\r\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\r\n",
      "Requirement already satisfied: setuptools in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20200917)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\r\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.50.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.3.0)\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n",
      "\u001B[38;5;2m✔ Linking successful\u001B[0m\r\n",
      "/home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages/en_core_web_sm\r\n",
      "-->\r\n",
      "/home/vladimir/miniconda3/envs/clearscale/lib/python3.7/site-packages/spacy/data/en\r\n",
      "You can now load the model via spacy.load('en')\r\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 275505/275505 [01:24<00:00, 3243.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_tokenize(data, tokenizer, lower, ngrams, cache=True):\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    for entry in tqdm.tqdm(data, 'lines', len(data)):\n",
    "        if lower:\n",
    "            entry['text'] = entry['text'].lower()\n",
    "        entry['text'] = tokenizer(entry['text'])\n",
    "        entry['text'] = list(ngrams_iterator(entry['text'], ngrams))\n",
    "    return data\n",
    "\n",
    "tokenizer = 'spacy'\n",
    "lower = True\n",
    "ngrams = 2\n",
    "\n",
    "train = data_tokenize(train, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 78715/78715 [00:24<00:00, 3154.55it/s]\n",
      "lines: 100%|██████████| 39359/39359 [00:12<00:00, 3069.20it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = data_tokenize(valid, tokenizer, lower, ngrams)\n",
    "test = data_tokenize(test, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:06<00:00, 45648.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_tokenized(data, filename):\n",
    "    with open(filename, 'wt') as f:\n",
    "        f.writelines(json.dumps(l) + '\\n' for l in tqdm.tqdm(data))\n",
    "\n",
    "save_tokenized(train, 'train_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78715/78715 [00:01<00:00, 45678.30it/s]\n",
      "100%|██████████| 39359/39359 [00:00<00:00, 42899.17it/s]\n"
     ]
    }
   ],
   "source": [
    "save_tokenized(valid, 'valid_tokenized.json')\n",
    "save_tokenized(test, 'test_tokenized.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load data if available"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_tokenized(filename):\n",
    "    with open(filename, 'rt') as f:\n",
    "        return [json.loads(l) for l in tqdm.tqdm(f.readlines())]\n",
    "\n",
    "if train is None:\n",
    "    train = load_tokenized('train_tokenized.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:10<00:00, 26010.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data, max_size=30000):\n",
    "    counter = Counter()\n",
    "    for entry in tqdm.tqdm(data):\n",
    "        counter.update(entry['text'])\n",
    "    return Vocab(counter, max_size)\n",
    "\n",
    "vocab = build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "create torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class JsonDataset(Dataset):\n",
    "    def __init__(self, filename, vocab):\n",
    "        self.filename = filename\n",
    "        self.vocab = vocab\n",
    "        self.label_dict = {i + 1: i for i in range(5)}\n",
    "        self.data_len = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with open(self.filename, 'rt') as f:\n",
    "            for i, l in enumerate(f):\n",
    "                if i == index:\n",
    "                    break\n",
    "        line = json.loads(l)\n",
    "        label = line['label']\n",
    "        label = self.label_dict[label]\n",
    "        text = line['text']\n",
    "        text = [torch.tensor(vocab[token]) for token in text]\n",
    "        return label, text\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.data_len:\n",
    "            with open(self.filename) as f:\n",
    "                for i, l in enumerate(f):\n",
    "                    pass\n",
    "            self.data_len = i + 1\n",
    "        return self.data_len\n",
    "\n",
    "train_dataset = JsonDataset('train_tokenized.json', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "valid_dataset = JsonDataset('valid_tokenized.json', vocab)\n",
    "test_dataset = JsonDataset('test_tokenized.json', vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}