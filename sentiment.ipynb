{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Reviews.csv')\n",
    "df = df[['Score', 'Text']]\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates('Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      5  I have bought several of the Vitality canned d...\n",
       "1      1  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2      4  This is a confection that has been around a fe...\n",
       "3      2  If you are looking for the secret ingredient i...\n",
       "4      5  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                393579\n",
       "unique                                               393579\n",
       "top       I have loved this gum since the first time I t...\n",
       "freq                                                      1\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels, reviews = df['Score'].to_numpy(), df['Text'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(arrays, ratios=(0.7, 0.2, 0.1)):\n",
    "    data_len = arrays[0].shape[0]\n",
    "    assert all(a.shape[0] == data_len for a in arrays[1:])\n",
    "    sizes = [r / sum(ratios) for r in ratios]\n",
    "    sizes = [int(s * data_len) for s in sizes[:-1]]\n",
    "    sizes.append(data_len - sum(sizes))\n",
    "    start = 0\n",
    "    finish = 0\n",
    "    splits = []\n",
    "    for s in sizes:\n",
    "        finish += s\n",
    "        splits.append([a[start:finish] for a in arrays])\n",
    "        start += s\n",
    "    return splits\n",
    "\n",
    "train, valid, test = split_data((labels, reviews), (0.7, 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_merge(data):\n",
    "    labels, text = data\n",
    "    return [{'label': int(l), 'text': row} for l, row in zip(labels, text)]\n",
    "\n",
    "train = data_merge(train)\n",
    "valid = data_merge(valid)\n",
    "test = data_merge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## tokenize text in datasets, add bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 275505/275505 [01:24<00:00, 3255.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_tokenize(data, tokenizer, lower, ngrams, cache=True):\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    for entry in tqdm.tqdm(data, 'lines', len(data)):\n",
    "        if lower:\n",
    "            entry['text'] = entry['text'].lower()\n",
    "        entry['text'] = tokenizer(entry['text'])\n",
    "        entry['text'] = list(ngrams_iterator(entry['text'], ngrams))\n",
    "    return data\n",
    "\n",
    "tokenizer = 'spacy'\n",
    "lower = True\n",
    "ngrams = 2\n",
    "\n",
    "train = data_tokenize(train, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 78715/78715 [00:24<00:00, 3256.86it/s]\n",
      "lines: 100%|██████████| 39359/39359 [00:11<00:00, 3292.76it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = data_tokenize(valid, tokenizer, lower, ngrams)\n",
    "test = data_tokenize(test, tokenizer, lower, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## save all data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:06<00:00, 42017.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_tokenized(data, filename):\n",
    "    with open(filename, 'wt') as f:\n",
    "        f.writelines(json.dumps(l) + '\\n' for l in tqdm.tqdm(data))\n",
    "\n",
    "save_tokenized(train, 'train_tokenized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78715/78715 [00:01<00:00, 43057.98it/s]\n",
      "100%|██████████| 39359/39359 [00:00<00:00, 42034.53it/s]\n"
     ]
    }
   ],
   "source": [
    "save_tokenized(valid, 'valid_tokenized.json')\n",
    "save_tokenized(test, 'test_tokenized.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train data from json if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_tokenized(filename):\n",
    "    with open(filename, 'rt') as f:\n",
    "        return [json.loads(l) for l in tqdm.tqdm(f.readlines())]\n",
    "\n",
    "try:\n",
    "    if train:\n",
    "        pass\n",
    "except NameError:\n",
    "    train = load_tokenized('train_tokenized.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275505/275505 [00:09<00:00, 27597.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data,\n",
    "                max_size=30000,  # x 100 emb_dim = about 3M model parameters\n",
    "                ):\n",
    "    counter = Counter()\n",
    "    for entry in tqdm.tqdm(data):\n",
    "        counter.update(entry['text'])\n",
    "    return Vocab(counter, max_size)\n",
    "\n",
    "vocab = build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## create torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████| 275505/275505 [00:36<00:00, 7496.79it/s]\n"
     ]
    }
   ],
   "source": [
    "class JsonDataset(Dataset):\n",
    "    def __init__(self, filename, vocab, preload):\n",
    "        self.filename = filename\n",
    "        self.vocab = vocab\n",
    "        self.label_dict = {i + 1: i for i in range(5)}\n",
    "        self.data_len = None\n",
    "        self.preload = preload\n",
    "        if self.preload:\n",
    "            self._preload_data()\n",
    "            \n",
    "    def _process_line(self, l):\n",
    "        l = json.loads(l)\n",
    "        label = l['label']\n",
    "        label = self.label_dict[label]\n",
    "        label = torch.tensor(label)\n",
    "        text = l['text']\n",
    "        text = torch.tensor(np.fromiter((self.vocab[token] for token in text),\n",
    "                            dtype='int'))\n",
    "        return label, text\n",
    "\n",
    "    def _preload_data(self):\n",
    "        self.data = []\n",
    "        with open(self.filename, 'rt') as f:\n",
    "            for l in tqdm.tqdm(f.readlines(), 'loading'):\n",
    "                self.data.append(self._process_line(l))\n",
    "        self.data_len = len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.preload:\n",
    "            return self.data[index]\n",
    "\n",
    "        with open(self.filename, 'rt') as f:\n",
    "            for i, l in enumerate(f):\n",
    "                if i == index:\n",
    "                    break\n",
    "        return self._process_line(l)\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.data_len:\n",
    "            with open(self.filename) as f:\n",
    "                for i, l in enumerate(f):\n",
    "                    pass\n",
    "            self.data_len = i + 1\n",
    "        return self.data_len\n",
    "\n",
    "train_dataset = JsonDataset('train_tokenized.json', vocab, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████| 78715/78715 [00:09<00:00, 8378.36it/s]\n",
      "loading: 100%|██████████| 39359/39359 [00:05<00:00, 6723.67it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = JsonDataset('valid_tokenized.json', vocab, True)\n",
    "test_dataset = JsonDataset('test_tokenized.json', vocab, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(train_dataset) == len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4),\n",
       " tensor([    5,    23,   188,   509,    12,     3,     0,  1101,   168,    85,\n",
       "           309,     6,    23,   173,    41,    57,     9,    45,    12,    43,\n",
       "           272,     2,     3,    52,  1204,    68,    35,     7,  8561,    78,\n",
       "             7,  2457,   833,     6,     8,  1236,   134,     2,    18, 26061,\n",
       "            13,  6014,     6,   152,     0,    14,    52,   134,    78,    10,\n",
       "           213,     2,    73,  3763, 18810,  7085,    58,     0,     0, 28801,\n",
       "          1013, 11736,  4716,   641,  1355,  3619,  2450, 16407,   157, 19358,\n",
       "          5927,  3090,  2636,    99,   381,     0,     0,  1932,   474,     0,\n",
       "             0,  1422,     0,     0,  8115,   161,  3327,     0,  1193,   428,\n",
       "             0,     0,     0,     0,  1237,     0,     0,   137,     0,   496,\n",
       "             0,  5994, 12876]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## create dataloaders for padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def padded_collate(batch, padding):\n",
    "    labels, texts = zip(*batch)\n",
    "    labels = torch.tensor(labels)\n",
    "    texts = pad_sequence(texts, padding_value=padding)\n",
    "    return labels, texts\n",
    "\n",
    "padding = vocab['<pad>']\n",
    "collate = partial(padded_collate, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=4)\n",
    "valid_iter = DataLoader(valid_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_iter  = DataLoader(test_dataset,\n",
    "                        batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate,\n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## add fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self, vocab_len, embed_dim, n_classes, padding):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_len, embed_dim, padding)\n",
    "        self.fc = nn.Linear(embed_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # shape = [seq_dim, batch_dim, embed_dim]\n",
    "        x = x.mean(0)\n",
    "        return self.fc(x)\n",
    "\n",
    "vocab_len = len(vocab)\n",
    "embed_dim = 100\n",
    "n_classes = 5\n",
    "model = TextModel(vocab_len, embed_dim, n_classes, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "number of parameters and output shape - sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of learnable parameters: 3000705\n"
     ]
    }
   ],
   "source": [
    "print('total number of learnable parameters: {}'.format(\n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output shape with batch size 256: torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "for l, t in train_iter:\n",
    "    break\n",
    "output = model(t)\n",
    "print('model output shape with batch size {}: {}'.format(\n",
    "    batch_size, output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_iter, model, optimizer, criterion, device):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for labels, texts in tqdm.tqdm(train_iter, 'train_batch', leave=False, position=0):\n",
    "        labels, texts = labels.to(device), texts.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(texts)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += (preds.argmax(1) == labels).sum().item()\n",
    "        total += labels.shape[0]\n",
    "\n",
    "    return total_loss / total, total_acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(valid_iter, model, criterion, device):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for labels, texts in tqdm.tqdm(valid_iter, 'valid_batch', leave=False, position=0):\n",
    "            labels, texts = labels.to(device), texts.to(device)\n",
    "\n",
    "            preds = model(texts)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += (preds.argmax(1) == labels).sum().item()\n",
    "            total += labels.shape[0]\n",
    "\n",
    "    return total_loss / total, total_acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001\n",
      "Training loss    : 0.00476\n",
      "Training acc     : 0.62\n",
      "Validation loss  : 0.00387\n",
      "Validation acc   : 0.65\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002\n",
      "Training loss    : 0.00362\n",
      "Training acc     : 0.66\n",
      "Validation loss  : 0.00332\n",
      "Validation acc   : 0.69\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003\n",
      "Training loss    : 0.00322\n",
      "Training acc     : 0.69\n",
      "Validation loss  : 0.00307\n",
      "Validation acc   : 0.71\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004\n",
      "Training loss    : 0.00302\n",
      "Training acc     : 0.71\n",
      "Validation loss  : 0.00294\n",
      "Validation acc   : 0.72\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005\n",
      "Training loss    : 0.00289\n",
      "Training acc     : 0.72\n",
      "Validation loss  : 0.00287\n",
      "Validation acc   : 0.73\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006\n",
      "Training loss    : 0.00280\n",
      "Training acc     : 0.73\n",
      "Validation loss  : 0.00282\n",
      "Validation acc   : 0.73\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007\n",
      "Training loss    : 0.00274\n",
      "Training acc     : 0.73\n",
      "Validation loss  : 0.00279\n",
      "Validation acc   : 0.74\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008\n",
      "Training loss    : 0.00268\n",
      "Training acc     : 0.74\n",
      "Validation loss  : 0.00277\n",
      "Validation acc   : 0.74\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009\n",
      "Training loss    : 0.00263\n",
      "Training acc     : 0.74\n",
      "Validation loss  : 0.00275\n",
      "Validation acc   : 0.74\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010\n",
      "Training loss    : 0.00260\n",
      "Training acc     : 0.75\n",
      "Validation loss  : 0.00274\n",
      "Validation acc   : 0.74\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011\n",
      "Training loss    : 0.00256\n",
      "Training acc     : 0.75\n",
      "Validation loss  : 0.00273\n",
      "Validation acc   : 0.74\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012\n",
      "Training loss    : 0.00253\n",
      "Training acc     : 0.76\n",
      "Validation loss  : 0.00273\n",
      "Validation acc   : 0.75\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013\n",
      "Training loss    : 0.00249\n",
      "Training acc     : 0.76\n",
      "Validation loss  : 0.00273\n",
      "Validation acc   : 0.75\n",
      "New best validation loss, saving model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014\n",
      "Training loss    : 0.00246\n",
      "Training acc     : 0.76\n",
      "Validation loss  : 0.00273\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015\n",
      "Training loss    : 0.00244\n",
      "Training acc     : 0.76\n",
      "Validation loss  : 0.00273\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016\n",
      "Training loss    : 0.00241\n",
      "Training acc     : 0.77\n",
      "Validation loss  : 0.00274\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017\n",
      "Training loss    : 0.00239\n",
      "Training acc     : 0.77\n",
      "Validation loss  : 0.00274\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018\n",
      "Training loss    : 0.00236\n",
      "Training acc     : 0.77\n",
      "Validation loss  : 0.00274\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019\n",
      "Training loss    : 0.00234\n",
      "Training acc     : 0.77\n",
      "Validation loss  : 0.00275\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020\n",
      "Training loss    : 0.00232\n",
      "Training acc     : 0.78\n",
      "Validation loss  : 0.00276\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021\n",
      "Training loss    : 0.00229\n",
      "Training acc     : 0.78\n",
      "Validation loss  : 0.00277\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022\n",
      "Training loss    : 0.00227\n",
      "Training acc     : 0.78\n",
      "Validation loss  : 0.00278\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023\n",
      "Training loss    : 0.00225\n",
      "Training acc     : 0.78\n",
      "Validation loss  : 0.00278\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_batch:   0%|          | 0/1077 [00:00<?, ?it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024\n",
      "Training loss    : 0.00223\n",
      "Training acc     : 0.79\n",
      "Validation loss  : 0.00280\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025\n",
      "Training loss    : 0.00221\n",
      "Training acc     : 0.79\n",
      "Validation loss  : 0.00281\n",
      "Validation acc   : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "best_loss = None\n",
    "best_path = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(train_iter, model, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(valid_iter, model, criterion, device)\n",
    "\n",
    "    print('Epoch: {:03d}'.format(epoch))\n",
    "    print('Training loss    : {:.5f}'.format(train_loss))\n",
    "    print('Training acc     : {:.2f}'.format(train_acc))\n",
    "    print('Validation loss  : {:.5f}'.format(valid_loss))\n",
    "    print('Validation acc   : {:.2f}'.format(valid_acc))\n",
    "\n",
    "    if best_loss is None or valid_loss < best_loss:\n",
    "        print('New best validation loss, saving model weights')\n",
    "        best_loss = valid_loss\n",
    "        old_path = best_path\n",
    "        best_path = 'textmodel5-epoch{:02d}-acc{:.2e}.pt'.format(epoch, valid_acc)\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        if old_path:\n",
    "            os.remove(old_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00281, test acc: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(test_iter, model, criterion, device)\n",
    "print('Test loss: {:.5f}, test acc: {:.2f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to predict scores for arbitrary reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(text, tokenizer, ngrams, vocab, device):\n",
    "    tokens = text.lower()\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    tokens = tokenizer(tokens)\n",
    "    tokens = ngrams_iterator(tokens, ngrams)\n",
    "    tokens = (vocab[t] for t in tokens)\n",
    "    tokens = torch.tensor(np.fromiter(tokens, dtype='int'))\n",
    "    \n",
    "    model.eval()\n",
    "    preds = model(tokens.to(device))\n",
    "    probs = nn.functional.softmax(preds, dim=0)\n",
    "    \n",
    "    print('Input review: {}'.format(text))\n",
    "    print('Predicted probas: {}'.format(probs.data))\n",
    "    print('Predicted score : {} / 5'.format(preds.argmax() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fn = partial(predict_score, tokenizer='spacy', ngrams=2, vocab=vocab, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input review: Nice product!\n",
      "Predicted probas: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0393e-24, 1.0000e+00],\n",
      "       device='cuda:0')\n",
      "Predicted score : 5 / 5\n"
     ]
    }
   ],
   "source": [
    "score_fn('Nice product!')              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input review: I was hoping for more, but I guess it's ok\n",
      "Predicted probas: tensor([2.2421e-44, 6.5471e-11, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0')\n",
      "Predicted score : 3 / 5\n"
     ]
    }
   ],
   "source": [
    "score_fn('I was hoping for more, but I guess it\\'s ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input review: Terrible handling, not usable\n",
      "Predicted probas: tensor([1.0000e+00, 9.8091e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0')\n",
      "Predicted score : 1 / 5\n"
     ]
    }
   ],
   "source": [
    "score_fn('Terrible handling, not usable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input review: Color almost makes up for a really mediocre material\n",
      "Predicted probas: tensor([4.3744e-12, 1.0000e+00, 1.3811e-13, 1.1236e-20, 6.6669e-33],\n",
      "       device='cuda:0')\n",
      "Predicted score : 2 / 5\n"
     ]
    }
   ],
   "source": [
    "score_fn('Color almost makes up for a really mediocre material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input review: It seems perfect, but the price is too steep for my taste\n",
      "Predicted probas: tensor([4.9174e-35, 2.5035e-14, 9.9802e-01, 1.9841e-03, 7.0943e-25],\n",
      "       device='cuda:0')\n",
      "Predicted score : 3 / 5\n"
     ]
    }
   ],
   "source": [
    "score_fn('It seems perfect, but the price is too steep for my taste')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
