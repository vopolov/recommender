{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.datasets import TextClassificationDataset\n",
    "from torchtext.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Reviews.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df[['Score', 'Text']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('Text')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Score                                               Text\n0      5  I have bought several of the Vitality canned d...\n1      1  Product arrived labeled as Jumbo Salted Peanut...\n2      4  This is a confection that has been around a fe...\n3      2  If you are looking for the secret ingredient i...\n4      5  Great taffy at a great price.  There was a wid...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "count                                                393579\nunique                                               393579\ntop       I realize all at once that I've been eating (a...\nfreq                                                      1\nName: Text, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 1, 4, 2, 3])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## build dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "labels, reviews = df['Score'].to_numpy(), df['Text'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "make splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def split_data(arrays, ratios=(0.7, 0.2, 0.1)):\n",
    "    data_len = arrays[0].shape[0]\n",
    "    assert all(a.shape[0] == data_len for a in arrays[1:])\n",
    "    sizes = [r / sum(ratios) for r in ratios]\n",
    "    sizes = [int(s * data_len) for s in sizes[:-1]]\n",
    "    sizes.append(data_len - sum(sizes))\n",
    "    start = 0\n",
    "    finish = 0\n",
    "    splits = []\n",
    "    for s in sizes:\n",
    "        finish += s\n",
    "        splits.append([a[start:finish] for a in arrays])\n",
    "        start += s\n",
    "    return splits\n",
    "\n",
    "train, valid, test = split_data((labels, reviews), (0.7, 0.2, 0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def data_merge(data):\n",
    "    labels, text = data\n",
    "    labels = [int(l) for l in labels]\n",
    "    text = [row for row in text]\n",
    "    return zip(labels, text)\n",
    "\n",
    "train = data_merge(train)\n",
    "valid = data_merge(valid)\n",
    "test = data_merge(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tokenize text in datasets, add bigrams"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python -m spacy download en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 275505/275505 [01:18<00:00, 3512.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_tokenize(data, tokenizer, lower, ngrams):\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    labels, text = zip(*data)\n",
    "    if lower:\n",
    "        text = (row.lower() for row in text)\n",
    "    text = (tokenizer(row) for row in text)\n",
    "    text = [list(ngrams_iterator(row, ngrams)) for row in\n",
    "            tqdm.tqdm(text, 'lines', len(labels))]\n",
    "    return zip(labels, text)\n",
    "\n",
    "tokenizer = 'spacy'\n",
    "lower = True\n",
    "ngrams = 2\n",
    "\n",
    "train = data_tokenize(train, tokenizer, lower, ngrams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lines: 100%|██████████| 78715/78715 [00:22<00:00, 3453.42it/s]\n",
      "lines: 100%|██████████| 39359/39359 [00:11<00:00, 3470.43it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = data_tokenize(valid, tokenizer, lower, ngrams)\n",
    "test = data_tokenize(test, tokenizer, lower, ngrams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "create vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def build_vocab(data, max_size=10000):\n",
    "    counter = Counter()\n",
    "    for label, row in data:\n",
    "        counter.update(row)\n",
    "    return Vocab(counter, max_size)\n",
    "\n",
    "vocab = build_vocab(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "create torch datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['this',\n 'saltwater',\n 'taffy',\n 'had',\n 'great',\n 'flavors',\n 'and',\n 'was',\n 'very',\n 'soft',\n 'and',\n 'chewy',\n '.',\n ' ',\n 'each',\n 'candy',\n 'was',\n 'individually',\n 'wrapped',\n 'well',\n '.',\n ' ',\n 'none',\n 'of',\n 'the',\n 'candies',\n 'were',\n 'stuck',\n 'together',\n ',',\n 'which',\n 'did',\n 'happen',\n 'in',\n 'the',\n 'expensive',\n 'version',\n ',',\n 'fralinger',\n \"'s\",\n '.',\n ' ',\n 'would',\n 'highly',\n 'recommend',\n 'this',\n 'candy',\n '!',\n ' ',\n 'i',\n 'served',\n 'it',\n 'at',\n 'a',\n 'beach',\n '-',\n 'themed',\n 'party',\n 'and',\n 'everyone',\n 'loved',\n 'it',\n '!',\n 'this saltwater',\n 'saltwater taffy',\n 'taffy had',\n 'had great',\n 'great flavors',\n 'flavors and',\n 'and was',\n 'was very',\n 'very soft',\n 'soft and',\n 'and chewy',\n 'chewy .',\n '.  ',\n '  each',\n 'each candy',\n 'candy was',\n 'was individually',\n 'individually wrapped',\n 'wrapped well',\n 'well .',\n '.  ',\n '  none',\n 'none of',\n 'of the',\n 'the candies',\n 'candies were',\n 'were stuck',\n 'stuck together',\n 'together ,',\n ', which',\n 'which did',\n 'did happen',\n 'happen in',\n 'in the',\n 'the expensive',\n 'expensive version',\n 'version ,',\n ', fralinger',\n \"fralinger 's\",\n \"'s .\",\n '.  ',\n '  would',\n 'would highly',\n 'highly recommend',\n 'recommend this',\n 'this candy',\n 'candy !',\n '!  ',\n '  i',\n 'i served',\n 'served it',\n 'it at',\n 'at a',\n 'a beach',\n 'beach -',\n '- themed',\n 'themed party',\n 'party and',\n 'and everyone',\n 'everyone loved',\n 'loved it',\n 'it !']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}